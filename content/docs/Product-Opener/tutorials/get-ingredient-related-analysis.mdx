---
title: "Ingredient Analysis"
description: "Complete guide to getting ingredient-related analysis including palm oil, vegan status, allergens, additives, and NOVA processing levels for products."
---

import { Callout } from 'fumadocs-ui/components/callout';
import { Card, Cards } from 'fumadocs-ui/components/card';
import { Step, Steps } from 'fumadocs-ui/components/steps';
import { Tab, Tabs } from 'fumadocs-ui/components/tabs';

<Card title="Complete Documentation" href="https://docs.google.com/document/d/1avnxJr8_m6OjRBt0vgwBzlzaZB7Q6z14t0taMKIrkp0/edit">
Access the full Google Doc with detailed implementation examples
</Card>

## Benefits

You can get information about absence or unawareness of the presence of:

<Tabs items={['Food Properties', 'Dietary Information', 'Processing Levels']}>
<Tab value="Food Properties">
**Palm oil**: `palm-oil-free`, `palm-oil`, `palm-oil-content-unknown`, `may-contain-palm-oil`
</Tab>
<Tab value="Dietary Information">
**Vegetarian ingredients**: `vegetarian`, `non-vegetarian`, `vegetarian-status-unknown`, `maybe-vegetarian`

**Vegan ingredients**: `vegan`, `non-vegan`, `vegan-status-unknown`, `maybe-vegan`
</Tab>
<Tab value="Processing Levels">
- Level of food processing (Nova)
- Allergens  
- Additives
</Tab>
</Tabs>

<Callout type="warn">
**Parsing Limitations**

Parsing might not be perfect and the ingredient detection might have issues in some languages. For more information on how you can help improve it, read: [ingredients.txt taxonomy](https://github.com/openfoodfacts/openfoodfacts-server/blob/master/taxonomies/ingredients.txt)
</Callout>

## Introduction

<Callout>
**Complete User Flow**

- If you can't get the information on a specific product, you can get your user to send photos and data, that will then be processed by Open Food Facts AI and contributors to get the computed result you want to show them
- You can implement the complete flow so that they get immediately the result with some effort on their side
- That will ensure user satisfaction
</Callout>

<Callout type="info">
**SDK Implementation**

Most of the operations described below are implemented in the openfoodfacts-dart plugin, but as individual operations, not as a coherent pipe
</Callout>

<Callout>
**Flow Diagram**

Schema of the ingredients flow - diagram available at: [Google Drawings](https://docs.google.com/drawings/d/12345/export/png)
</Callout>

## Flow

### The product does not exist

<Card title="Adding Products Tutorial" href="./adding-missing-products.mdx">
Learn how to add new products to the database
</Card>

### The product does exist: Get the status of the product and show prompts in case of incomplete ingredients or category

```javascript title="Status Check Logic"
if ( 
  status = category-to-be-completed && 
  status = ingredients-to-be-completed 
)
then "Add ingredients and a category to see the level of food processing and potential additives"

if ( 
  status = category-to-be-completed
)
then "Add a category to see the level of food processing and potential additives"

if ( 
  status = ingredients-to-be-completed 
)
then "Add ingredients to see the level of food processing and potential additives"
```

<Callout>
**Next Step**

Once the user has entered one of your completion flows, proceed to the next step
</Callout>

### Upload ingredient photo

<Cards>
<Card title="Photo Upload Tutorial" href="../tutorial-uploading-photo-to-a-product.mdx" description="Follow our dedicated tutorial on photo upload" />
<Card title="DART SDK Support" description="The DART SDK offers support for photo upload" />
</Cards>

<Callout>
**SDK Implementation**

We encourage you to implement photo upload in one of the official Open Food Facts SDKs if it's not supported yet
</Callout>

<Steps>
<Step>
**Language-Specific Cropping**

Ensure that your users crop language by language, or take all languages at once, but you perform server side cropping on one specific language before performing the OCR
</Step>

<Step>
**ML Language Detection**

We're working on a ML solution to detect languages and performing auto-crops per language ([contact us](mailto:reuse@openfoodfacts.org) to learn more)
</Step>

<Step>
**Optimize at Upload**

If you want to skip the next step, try to get rotation, cropping right at this stage
</Step>
</Steps>

### Adjusting the photo (Selecting, Rotating and Cropping)

Selecting, cropping and rotating photos are non-destructive actions. That means, the original version of the image uploaded to the system is kept as is. The subsequent changes made to the image are also stored as versions of the original image.

The actions described in this topic do not modify the image, but provide metadata on how to use it (the data of the corners in the case of selection and the data of the rotation). That is, you send an image to the API, provide an id, you define, for example, the cropping and rotation parameters and as a response, the server generates a new image as requested and you can call this new version of the image.

#### Selecting photos
[Please look at the specific tutorial](../tutorial-uploading-photo-to-a-product.mdx)

#### Rotating a photo
[Please look at the reference](https://openfoodfacts.github.io/openfoodfacts-server/api/ref-v2/#get-/cgi/product_image_crop.pl)

#### Cropping Photos
{/* Note: Cropping is only relevant for editing already selected images. You need to upload it first to the system, select it, retrieve its id, and then crop it. */}

This is a non destructive crop. If there's an issue with the image, you should report it using the dedicated NutriPatrol API. Moderators will either perform a destructive crop, or more likely delete the image.

- [Please look at the reference](https://openfoodfacts.github.io/openfoodfacts-server/api/ref-v2/#post-/cgi/product_image_crop.pl)

#### Unselecting photos
[Please look at the reference](https://openfoodfacts.github.io/openfoodfacts-server/api/ref-v2/#post-/cgi/product_image_unselect.pl)

### Get the Optical Character Recognition (OCR) output of the ingredients photo

Open Food Facts uses optical character recognition (OCR) to retrieve ingredient data and other information (using Robotoff) from the photos of the product labels.

**Notes**:
- The OCR may contain errors. Encourage your users to correct the output using the ingredients WRITE API
- You can also use your own on-device OCR, especially if you're superconfident about it performing better than the server's cloudvision and if you plan to send a high number of queries
- Please DO NOT translate and send us the OCR output. We want to store only actual data. If you want translated version of the ingredient list, please send us an email to [reuse@openfoodfacts.org](mailto:reuse@openfoodfacts.org)

#### API solution
[Please look at the reference](https://openfoodfacts.github.io/openfoodfacts-server/api/ref-v2/#get-/cgi/ingredients.pl)

#### Dart SDK solution
- [OcrIngredientsResult class](https://openfoodfacts.github.io/openfoodfacts-dart/model_OcrIngredientsResult/OcrIngredientsResult-class.html)
- [OcrField class](https://openfoodfacts.github.io/openfoodfacts-dart/utils_OcrField/OcrField-class.html)
- [OcrFieldExtension](https://openfoodfacts.github.io/openfoodfacts-dart/utils_OcrField/OcrFieldExtension.html)

### Present the result of the Optical Character Recognition (OCR) output to your user for human review

- Create a UI that encourages careful review, and encourages dropping the output if it's not right
- Create a UI that encourages taking a less blurry, better framed photo to fix the output
- Create a UI that handles multilinguism well

### Send the ingredients
[Please look at the reference located](https://openfoodfacts.github.io/openfoodfacts-server/api/ref-v2/#post-/cgi/product_jqm2.pl)

### Refresh product to display the result to your user
[Please look at the reference](https://openfoodfacts.github.io/openfoodfacts-server/api/ref-v3/#get-/api/v3/product/-barcode-)

{/* Note: An ingredient analysis result image would be displayed here, showing the computed nutritional information and processing levels */}
